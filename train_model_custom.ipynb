{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "24773cdc-4bbe-48c3-9910-8b39c38bfc7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-06 04:16:34.399785: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-11-06 04:16:35.263758: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import datasets, layers, models\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "import keras\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import *\n",
    "from keras.utils import Sequence\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from qkeras import *\n",
    "\n",
    "from keras.utils import Sequence\n",
    "from keras.callbacks import CSVLogger\n",
    "from keras.callbacks import EarlyStopping\n",
    "\n",
    "import os\n",
    "import random\n",
    "\n",
    "pi = 3.14159265359\n",
    "\n",
    "maxval=1e9\n",
    "minval=1e-9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1ac065e8-fcf2-44a0-8dee-e1e44e605137",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataprep import *\n",
    "#from dataloaders.OptimizedDataGenerator import OptimizedDataGenerator\n",
    "from loss import *\n",
    "from models.models_bnorm import *"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a01a8b2d-8c82-46f3-94b6-0b392b62fd82",
   "metadata": {},
   "source": [
    "# Scaling Lists for Different Pixel Pitches:\n",
    "* 100x25x100 um:  [150.0, 37.5, 10.0, 1.22]\n",
    "* 50x25x100 um:   [75.0, 37.5, 10.0, 1.22]\n",
    "* 50x20x100 um:   [75.0, 30.0, 10.0, 1.22]\n",
    "* 50x15x100 um:   [75.0, 22.5, 10.0, 1.22]\n",
    "* 50x12.5x100 um: [75.0, 18.75, 10.0, 1.22]\n",
    "* 50x25x100 um:   [75.0, 15.0, 10.0, 1.22]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9e1a0184-55a3-4294-b0df-b3067d9bb72f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Files: 100%|██████████| 40/40 [12:13<00:00, 18.34s/it]\n",
      "Processing Files: 100%|██████████| 10/10 [01:44<00:00, 10.42s/it]\n"
     ]
    }
   ],
   "source": [
    "batch_size = 100\n",
    "val_batch_size = 100\n",
    "train_file_size = 40\n",
    "val_file_size = 10\n",
    "\n",
    "training_generator = CustomDataGenerator(\n",
    "    data_directory_path = \"/data/dajiang/smartPixels/dataset_2s/dataset_2s_50x12P5_parquets/unflipped/recon3D/\",\n",
    "    labels_directory_path = \"/data/dajiang/smartPixels/dataset_2s/dataset_2s_50x12P5_parquets/unflipped/labels/\",\n",
    "    is_directory_recursive = False,\n",
    "    file_type = \"parquet\",\n",
    "    data_format = \"3D\",\n",
    "    batch_size = batch_size,\n",
    "    file_count = train_file_size,\n",
    "    to_standardize= True,\n",
    "    include_y_local= False,\n",
    "    labels_list = ['x-midplane','y-midplane','cotAlpha','cotBeta'],\n",
    "    scaling_list = [75.0, 18.75, 10.0, 1.22],\n",
    "    input_shape = (20,13,21),\n",
    "    transpose = (0,2,3,1),\n",
    "    files_from_end=True,\n",
    "    shuffle= True\n",
    "\n",
    ")\n",
    "\n",
    "validation_generator = CustomDataGenerator(\n",
    "    data_directory_path = \"/data/dajiang/smartPixels/dataset_2s/dataset_2s_50x12P5_parquets/unflipped/recon3D/\",\n",
    "    labels_directory_path = \"/data/dajiang/smartPixels/dataset_2s/dataset_2s_50x12P5_parquets/unflipped/labels/\",\n",
    "    is_directory_recursive = False,\n",
    "    file_type = \"parquet\",\n",
    "    data_format = \"3D\",\n",
    "    batch_size = val_batch_size,\n",
    "    file_count = val_file_size,\n",
    "    to_standardize= True,\n",
    "    include_y_local= False,\n",
    "    labels_list = ['x-midplane','y-midplane','cotAlpha','cotBeta'],\n",
    "    scaling_list = [75.0, 18.75, 10.0, 1.22],\n",
    "    input_shape = (20,13,21),\n",
    "    transpose = (0,2,3,1),\n",
    "    files_from_end=True,\n",
    "    shuffle= True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b9fd3960-c7f1-4d6c-b7e0-0c4c833797d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-06 04:32:31.174898: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 3234 MB memory:  -> device: 0, name: NVIDIA A100-SXM4-40GB MIG 1g.5gb, pci bus id: 0000:81:00.0, compute capability: 8.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 13, 21, 20)]      0         \n",
      "                                                                 \n",
      " q_separable_conv2d (QSepar  (None, 11, 19, 5)         285       \n",
      " ableConv2D)                                                     \n",
      "                                                                 \n",
      " q_batch_normalization (QBa  (None, 11, 19, 5)         20        \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " q_activation (QActivation)  (None, 11, 19, 5)         0         \n",
      "                                                                 \n",
      " q_conv2d (QConv2D)          (None, 11, 19, 5)         30        \n",
      "                                                                 \n",
      " q_batch_normalization_1 (Q  (None, 11, 19, 5)         20        \n",
      " BatchNormalization)                                             \n",
      "                                                                 \n",
      " q_activation_1 (QActivatio  (None, 11, 19, 5)         0         \n",
      " n)                                                              \n",
      "                                                                 \n",
      " average_pooling2d (Average  (None, 3, 6, 5)           0         \n",
      " Pooling2D)                                                      \n",
      "                                                                 \n",
      " q_activation_2 (QActivatio  (None, 3, 6, 5)           0         \n",
      " n)                                                              \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 90)                0         \n",
      "                                                                 \n",
      " q_dense (QDense)            (None, 16)                1456      \n",
      "                                                                 \n",
      " q_batch_normalization_2 (Q  (None, 16)                64        \n",
      " BatchNormalization)                                             \n",
      "                                                                 \n",
      " q_activation_3 (QActivatio  (None, 16)                0         \n",
      " n)                                                              \n",
      "                                                                 \n",
      " q_dense_1 (QDense)          (None, 16)                272       \n",
      "                                                                 \n",
      " q_batch_normalization_3 (Q  (None, 16)                64        \n",
      " BatchNormalization)                                             \n",
      "                                                                 \n",
      " q_activation_4 (QActivatio  (None, 16)                0         \n",
      " n)                                                              \n",
      "                                                                 \n",
      " q_dense_2 (QDense)          (None, 14)                238       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2449 (9.57 KB)\n",
      "Trainable params: 2365 (9.24 KB)\n",
      "Non-trainable params: 84 (336.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# compiles model\n",
    "model=CreateModel((13,21,20),n_filters=5,pool_size=3)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "870b8741-98fd-4e1e-bc29-7b9fcbb9b640",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=Adam(learning_rate=0.001), loss=custom_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d3ecb0d-5db2-4610-bd58-e55d06f049a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/600\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-06 04:33:05.265410: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:432] Loaded cuDNN version 8906\n",
      "2024-11-06 04:33:05.329176: I tensorflow/tsl/platform/default/subprocess.cc:304] Start cannot spawn child process: No such file or directory\n",
      "2024-11-06 04:33:05.480010: I tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:606] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.\n",
      "2024-11-06 04:33:05.490630: I tensorflow/core/util/cuda_solvers.cc:179] Creating GpuSolver handles for stream 0x88a7e90\n",
      "2024-11-06 04:33:05.506418: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7f667f0cd700 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2024-11-06 04:33:05.506450: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): NVIDIA A100-SXM4-40GB MIG 1g.5gb, Compute Capability 8.0\n",
      "2024-11-06 04:33:05.511043: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:255] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2024-11-06 04:33:05.567780: I tensorflow/tsl/platform/default/subprocess.cc:304] Start cannot spawn child process: No such file or directory\n",
      "2024-11-06 04:33:05.614754: I ./tensorflow/compiler/jit/device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19902/19902 - 862s - loss: -5.3609e+01 - val_loss: -1.7453e+02 - 862s/epoch - 43ms/step\n",
      "Epoch 2/600\n"
     ]
    }
   ],
   "source": [
    "# training\n",
    "base_dir = \"./weights-50x12P5-bs100-custom-checkpoints\"\n",
    "os.mkdir(base_dir)\n",
    "checkpoint_filepath = base_dir + '/weights.{epoch:02d}-t{loss:.2f}-v{val_loss:.2f}.hdf5'\n",
    "mcp = tf.keras.callbacks.ModelCheckpoint(\n",
    "    filepath=checkpoint_filepath,\n",
    "    save_weights_only=True,\n",
    "    monitor='val_loss',\n",
    "    save_best_only=False,\n",
    ")\n",
    "\n",
    "class ScalePrintingCallback(keras.callbacks.Callback):    \n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        scale_layer = self.model.layers[-1]\n",
    "        print(\n",
    "            f\"scaling layer ({epoch}):\", \n",
    "            scale_layer.scale, \n",
    "            tf.math.softplus(scale_layer.scale)\n",
    "        )\n",
    "\n",
    "print_scale = ScalePrintingCallback()\n",
    "\n",
    "history = model.fit(x=training_generator,\n",
    "                    validation_data=validation_generator,\n",
    "                    callbacks=[mcp],\n",
    "                    epochs=600,\n",
    "                    shuffle=False, # shuffling now occurs within the data-loader\n",
    "                    verbose=2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8",
   "language": "python",
   "name": "py38"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
