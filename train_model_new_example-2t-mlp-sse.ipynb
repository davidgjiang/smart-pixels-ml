{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "24773cdc-4bbe-48c3-9910-8b39c38bfc7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-17 19:08:15.654104: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-06-17 19:08:16.597014: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import datasets, layers, models\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "import tensorflow.keras\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import *\n",
    "from keras.utils import Sequence\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from qkeras import *\n",
    "\n",
    "from keras.utils import Sequence\n",
    "from keras.callbacks import CSVLogger\n",
    "from keras.callbacks import EarlyStopping\n",
    "\n",
    "import os\n",
    "import random\n",
    "from datetime import datetime\n",
    "import time\n",
    "\n",
    "pi = 3.14159265359\n",
    "\n",
    "maxval=1e9\n",
    "minval=1e-9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1ac065e8-fcf2-44a0-8dee-e1e44e605137",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataloaders.OptimizedDataGenerator_v2 import OptimizedDataGenerator\n",
    "from loss import *\n",
    "from mlp_encoder_model import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "80abd7d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 10\n",
    "tf.random.set_seed(seed)\n",
    "random.seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bfbc64d0-998a-4022-b4f5-e886c4c07941",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_base_dir = \"/data/dajiang/smart-pixels/dataset_3sr/shuffled/dataset_3sr_16x16_50x12P5_parquets/contained/\"\n",
    "tfrecords_base_dir = os.path.join(dataset_base_dir, \"TFR_files\", \"2t\")\n",
    "\n",
    "dataset_train_dir = os.path.join(dataset_base_dir, \"train\")\n",
    "dataset_validation_dir = os.path.join(dataset_base_dir, \"test\")\n",
    "tfrecords_dir_train = os.path.join(tfrecords_base_dir, \"TFR_train_slim\")\n",
    "tfrecords_dir_val   = os.path.join(tfrecords_base_dir, \"TFR_val_slim\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "80c17a48-9308-40e4-a126-5478659cfedd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training files: 80\n",
      "Number of validation files: 20\n"
     ]
    }
   ],
   "source": [
    "print(f'Number of training files: {len(os.listdir(dataset_train_dir))}')\n",
    "print(f'Number of validation files: {len(os.listdir(dataset_validation_dir))}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "af8bb9b7-c75e-489d-83bc-ad517c652aab",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "batch_size = 5000\n",
    "val_batch_size = 5000\n",
    "train_file_size = len(os.listdir(dataset_train_dir))\n",
    "val_file_size = len(os.listdir(dataset_validation_dir))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d0b6afa7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading metadata from /data/dajiang/smart-pixels/dataset_3sr/shuffled/dataset_3sr_16x16_50x12P5_parquets/contained/TFR_files/2t/TFR_val_slim/metadata.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Quantization is False in data generator. This may affect model performance.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Validation generator 0.24593091011047363 seconds ---\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "validation_generator = OptimizedDataGenerator(\n",
    "    dataset_base_dir = dataset_validation_dir,\n",
    "    file_type = \"parquet\",\n",
    "    data_format = \"3D\",\n",
    "    batch_size = val_batch_size,\n",
    "    file_count = val_file_size,\n",
    "    to_standardize= True,\n",
    "    include_y_local= False,\n",
    "    labels_list = ['x-midplane','y-midplane','cotBeta'],\n",
    "    input_shape = (2,16,16), # (20,16,16),\n",
    "    transpose = (0,2,3,1),\n",
    "    shuffle = False, \n",
    "    files_from_end=True,\n",
    "\n",
    "    tfrecords_dir = tfrecords_dir_val,\n",
    "    use_time_stamps = [0,19],\n",
    "    max_workers = 2,\n",
    "    load_from_tfrecords_dir = tfrecords_dir_val\n",
    ")\n",
    "\n",
    "print(\"--- Validation generator %s seconds ---\" % (time.time() - start_time))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "548efe18",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Quantization is False in data generator. This may affect model performance.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading metadata from /data/dajiang/smart-pixels/dataset_3sr/shuffled/dataset_3sr_16x16_50x12P5_parquets/contained/TFR_files/2t/TFR_train_slim/metadata.json\n",
      "--- Training generator 0.16203856468200684 seconds ---\n"
     ]
    }
   ],
   "source": [
    "# training generator\n",
    "start_time = time.time()\n",
    "training_generator = OptimizedDataGenerator(\n",
    "    dataset_base_dir = dataset_train_dir,\n",
    "    file_type = \"parquet\",\n",
    "    data_format = \"3D\",\n",
    "    batch_size = batch_size,\n",
    "    file_count = train_file_size,\n",
    "    to_standardize= True,\n",
    "    include_y_local= False,\n",
    "    labels_list = ['x-midplane','y-midplane','cotBeta'],\n",
    "    input_shape = (2,16,16), # (20,16,16),\n",
    "    transpose = (0,2,3,1),\n",
    "    shuffle = False, # True \n",
    "\n",
    "    tfrecords_dir = tfrecords_dir_train,\n",
    "    use_time_stamps = [0,19],\n",
    "    max_workers = 2,\n",
    "    load_from_tfrecords_dir = tfrecords_dir_train\n",
    ")\n",
    "print(\"--- Training generator %s seconds ---\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "248e5d17-2a8f-4e8c-871a-65a0ab3794b4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Quantization is True in data generator. This may affect model performance.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading metadata from /data/dajiang/smart-pixels/dataset_3sr/shuffled/dataset_3sr_16x16_50x12P5_parquets/contained/TFR_files/2t/TFR_train_slim/metadata.json\n",
      "Loading metadata from /data/dajiang/smart-pixels/dataset_3sr/shuffled/dataset_3sr_16x16_50x12P5_parquets/contained/TFR_files/2t/TFR_val_slim/metadata.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Quantization is True in data generator. This may affect model performance.\n"
     ]
    }
   ],
   "source": [
    "training_generator = OptimizedDataGenerator(\n",
    "    load_from_tfrecords_dir = tfrecords_dir_train,\n",
    "    shuffle = True,\n",
    "    seed = seed,\n",
    "    quantize = True\n",
    ")\n",
    "\n",
    "validation_generator = OptimizedDataGenerator(\n",
    "    load_from_tfrecords_dir = tfrecords_dir_val,\n",
    "    shuffle = True,\n",
    "    seed = seed,\n",
    "    quantize = True\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c72cef1b-61db-489f-83bb-039a46861094",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-17 19:08:59.232723: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 3234 MB memory:  -> device: 0, name: NVIDIA A100-SXM4-40GB MIG 1g.5gb, pci bus id: 0000:c1:00.0, compute capability: 8.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"smrtpxl_regression\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                Output Shape                 Param #   Connected to                  \n",
      "==================================================================================================\n",
      " input_pxls/ (InputLayer)    [(None, 16, 16, 2)]          0         []                            \n",
      "                                                                                                  \n",
      " average_pooling2d (Average  (None, 16, 1, 2)             0         ['input_pxls/[0][0]']         \n",
      " Pooling2D)                                                                                       \n",
      "                                                                                                  \n",
      " average_pooling2d_1 (Avera  (None, 1, 16, 2)             0         ['input_pxls/[0][0]']         \n",
      " gePooling2D)                                                                                     \n",
      "                                                                                                  \n",
      " flatten (Flatten)           (None, 32)                   0         ['average_pooling2d[0][0]']   \n",
      "                                                                                                  \n",
      " flatten_1 (Flatten)         (None, 32)                   0         ['average_pooling2d_1[0][0]'] \n",
      "                                                                                                  \n",
      " q_dense (QDense)            (None, 16)                   528       ['flatten[0][0]']             \n",
      "                                                                                                  \n",
      " q_dense_1 (QDense)          (None, 16)                   528       ['flatten_1[0][0]']           \n",
      "                                                                                                  \n",
      " q_activation (QActivation)  (None, 16)                   0         ['q_dense[0][0]']             \n",
      "                                                                                                  \n",
      " q_activation_1 (QActivatio  (None, 16)                   0         ['q_dense_1[0][0]']           \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " concatenate (Concatenate)   (None, 32)                   0         ['q_activation[0][0]',        \n",
      "                                                                     'q_activation_1[0][0]']      \n",
      "                                                                                                  \n",
      " q_dense_2 (QDense)          (None, 16)                   528       ['concatenate[0][0]']         \n",
      "                                                                                                  \n",
      " q_activation_2 (QActivatio  (None, 16)                   0         ['q_dense_2[0][0]']           \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " flatten_var (Flatten)       (None, 16)                   0         ['q_activation_2[0][0]']      \n",
      "                                                                                                  \n",
      " dense_1 (QDense)            (None, 16)                   272       ['flatten_var[0][0]']         \n",
      "                                                                                                  \n",
      " activation_tanh_2 (QActiva  (None, 16)                   0         ['dense_1[0][0]']             \n",
      " tion)                                                                                            \n",
      "                                                                                                  \n",
      " dense_2 (QDense)            (None, 16)                   272       ['activation_tanh_2[0][0]']   \n",
      "                                                                                                  \n",
      " activation_tanh_3 (QActiva  (None, 16)                   0         ['dense_2[0][0]']             \n",
      " tion)                                                                                            \n",
      "                                                                                                  \n",
      " dense_3 (QDense)            (None, 3)                    51        ['activation_tanh_3[0][0]']   \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 2179 (8.51 KB)\n",
      "Trainable params: 2179 (8.51 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model=CreateModel((16,16,2))\n",
    "model.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(learning_rate=1e-3),\n",
    "    loss=custom_sse_loss\n",
    ")\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "641b38fa-0cfb-4e17-859f-6570c889d7bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model fingerprint: 34c2da80\n"
     ]
    }
   ],
   "source": [
    "# training\n",
    "pitch = '50x12P5'\n",
    "fingerprint = '%08x' % random.randrange(16**8)\n",
    "base_dir = '/home/dajiang/smart-pixels-ml/weights/dataset_3src_16x16_weights/'\n",
    "weights_dir = base_dir + 'weights-{}-bs{}-{}-2t-mlp-sse-slim-checkpoints'.format(pitch, batch_size, fingerprint)\n",
    "\n",
    "# create output directories\n",
    "if os.path.isdir(base_dir):\n",
    "    os.mkdir(weights_dir)\n",
    "else:\n",
    "    os.mkdir(base_dir)\n",
    "    os.mkdir(weights_dir)\n",
    "    \n",
    "checkpoint_filepath = weights_dir + '/weights.{epoch:02d}-t{loss:.2f}-v{val_loss:.2f}.hdf5'\n",
    "mcp = tf.keras.callbacks.ModelCheckpoint(\n",
    "    filepath=checkpoint_filepath,\n",
    "    save_weights_only=True,\n",
    "    monitor='val_loss',\n",
    "    save_best_only=False,\n",
    ")\n",
    "\n",
    "print('Model fingerprint: {}'.format(fingerprint))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d3ecb0d-5db2-4610-bd58-e55d06f049a6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-17 19:09:11.476960: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:432] Loaded cuDNN version 8906\n",
      "2025-06-17 19:09:11.486086: I tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:606] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.\n",
      "2025-06-17 19:09:11.518851: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7fd418aa2f60 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2025-06-17 19:09:11.518908: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): NVIDIA A100-SXM4-40GB MIG 1g.5gb, Compute Capability 8.0\n",
      "2025-06-17 19:09:11.523199: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:255] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2025-06-17 19:09:11.619354: I tensorflow/tsl/platform/default/subprocess.cc:304] Start cannot spawn child process: No such file or directory\n",
      "2025-06-17 19:09:11.675241: I ./tensorflow/compiler/jit/device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "84/84 [==============================] - 10s 84ms/step - loss: 773.3561 - val_loss: 301.3843\n",
      "Epoch 2/1000\n",
      "84/84 [==============================] - 7s 77ms/step - loss: 213.7697 - val_loss: 166.0788\n",
      "Epoch 3/1000\n",
      "84/84 [==============================] - 6s 77ms/step - loss: 143.3676 - val_loss: 125.6869\n",
      "Epoch 4/1000\n",
      "84/84 [==============================] - 7s 79ms/step - loss: 113.2783 - val_loss: 104.2026\n",
      "Epoch 5/1000\n",
      "84/84 [==============================] - 6s 76ms/step - loss: 96.2043 - val_loss: 92.0492\n",
      "Epoch 6/1000\n",
      "84/84 [==============================] - 6s 77ms/step - loss: 85.9248 - val_loss: 82.7736\n",
      "Epoch 7/1000\n",
      "84/84 [==============================] - 6s 76ms/step - loss: 78.4722 - val_loss: 76.1569\n",
      "Epoch 8/1000\n",
      "84/84 [==============================] - 6s 76ms/step - loss: 73.7495 - val_loss: 73.3386\n",
      "Epoch 9/1000\n",
      "84/84 [==============================] - 6s 75ms/step - loss: 69.1906 - val_loss: 68.5960\n",
      "Epoch 10/1000\n",
      "84/84 [==============================] - 6s 74ms/step - loss: 66.3473 - val_loss: 65.3500\n",
      "Epoch 11/1000\n",
      "84/84 [==============================] - 6s 74ms/step - loss: 63.9607 - val_loss: 65.0307\n",
      "Epoch 12/1000\n",
      "84/84 [==============================] - 6s 76ms/step - loss: 61.5103 - val_loss: 61.9961\n",
      "Epoch 13/1000\n",
      "84/84 [==============================] - 6s 75ms/step - loss: 60.0324 - val_loss: 59.6927\n",
      "Epoch 14/1000\n",
      "84/84 [==============================] - 6s 73ms/step - loss: 58.6584 - val_loss: 58.3343\n",
      "Epoch 15/1000\n",
      "84/84 [==============================] - 6s 74ms/step - loss: 57.1859 - val_loss: 58.0047\n",
      "Epoch 16/1000\n",
      "84/84 [==============================] - 6s 73ms/step - loss: 56.5921 - val_loss: 60.6430\n",
      "Epoch 17/1000\n",
      "84/84 [==============================] - 6s 75ms/step - loss: 56.1169 - val_loss: 58.4697\n",
      "Epoch 18/1000\n",
      "84/84 [==============================] - 6s 74ms/step - loss: 53.7664 - val_loss: 53.2071\n",
      "Epoch 19/1000\n",
      "84/84 [==============================] - 6s 74ms/step - loss: 52.2463 - val_loss: 52.8304\n",
      "Epoch 20/1000\n",
      "84/84 [==============================] - 6s 74ms/step - loss: 51.1819 - val_loss: 51.1965\n",
      "Epoch 21/1000\n",
      "84/84 [==============================] - 6s 75ms/step - loss: 50.2088 - val_loss: 50.5319\n",
      "Epoch 22/1000\n",
      "84/84 [==============================] - 6s 76ms/step - loss: 49.5455 - val_loss: 51.4528\n",
      "Epoch 23/1000\n",
      "84/84 [==============================] - 6s 74ms/step - loss: 48.9284 - val_loss: 49.1091\n",
      "Epoch 24/1000\n",
      "84/84 [==============================] - 6s 74ms/step - loss: 48.2460 - val_loss: 48.0261\n",
      "Epoch 25/1000\n",
      "84/84 [==============================] - 6s 77ms/step - loss: 47.5558 - val_loss: 48.4596\n",
      "Epoch 26/1000\n",
      "84/84 [==============================] - 6s 76ms/step - loss: 47.0433 - val_loss: 48.4393\n",
      "Epoch 27/1000\n",
      "84/84 [==============================] - 6s 74ms/step - loss: 46.8508 - val_loss: 46.0799\n",
      "Epoch 28/1000\n",
      "84/84 [==============================] - 7s 79ms/step - loss: 46.0692 - val_loss: 48.4401\n",
      "Epoch 29/1000\n",
      "84/84 [==============================] - 6s 76ms/step - loss: 45.6801 - val_loss: 45.6226\n",
      "Epoch 30/1000\n",
      "84/84 [==============================] - 6s 74ms/step - loss: 45.7279 - val_loss: 45.5295\n",
      "Epoch 31/1000\n",
      "84/84 [==============================] - 6s 72ms/step - loss: 44.9180 - val_loss: 44.9434\n",
      "Epoch 32/1000\n",
      "84/84 [==============================] - 6s 74ms/step - loss: 44.8372 - val_loss: 44.5403\n",
      "Epoch 33/1000\n",
      "84/84 [==============================] - 6s 77ms/step - loss: 44.4839 - val_loss: 45.2173\n",
      "Epoch 34/1000\n",
      "84/84 [==============================] - 6s 76ms/step - loss: 44.5209 - val_loss: 48.4969\n",
      "Epoch 35/1000\n",
      "84/84 [==============================] - 7s 79ms/step - loss: 44.6524 - val_loss: 45.7824\n",
      "Epoch 36/1000\n",
      "84/84 [==============================] - 6s 76ms/step - loss: 44.5305 - val_loss: 44.6889\n",
      "Epoch 37/1000\n",
      "84/84 [==============================] - 6s 76ms/step - loss: 43.6917 - val_loss: 45.5822\n",
      "Epoch 38/1000\n",
      "84/84 [==============================] - 7s 78ms/step - loss: 43.2956 - val_loss: 43.6637\n",
      "Epoch 39/1000\n",
      "84/84 [==============================] - 6s 75ms/step - loss: 43.2733 - val_loss: 43.3214\n",
      "Epoch 40/1000\n",
      "84/84 [==============================] - 6s 74ms/step - loss: 43.7558 - val_loss: 44.9718\n",
      "Epoch 41/1000\n",
      "84/84 [==============================] - 6s 74ms/step - loss: 44.0064 - val_loss: 48.3383\n",
      "Epoch 42/1000\n",
      "84/84 [==============================] - 6s 72ms/step - loss: 42.6113 - val_loss: 42.3380\n",
      "Epoch 43/1000\n",
      "84/84 [==============================] - 6s 73ms/step - loss: 41.8327 - val_loss: 42.6383\n",
      "Epoch 44/1000\n",
      "84/84 [==============================] - 6s 74ms/step - loss: 41.8600 - val_loss: 42.1487\n",
      "Epoch 45/1000\n",
      "84/84 [==============================] - 6s 72ms/step - loss: 41.6833 - val_loss: 42.4939\n",
      "Epoch 46/1000\n",
      "84/84 [==============================] - 6s 72ms/step - loss: 41.4511 - val_loss: 41.9455\n",
      "Epoch 47/1000\n",
      "84/84 [==============================] - 6s 72ms/step - loss: 41.5959 - val_loss: 41.9371\n",
      "Epoch 48/1000\n",
      "84/84 [==============================] - 6s 74ms/step - loss: 41.2927 - val_loss: 40.8105\n",
      "Epoch 49/1000\n",
      "84/84 [==============================] - 6s 74ms/step - loss: 41.1394 - val_loss: 40.6764\n",
      "Epoch 50/1000\n",
      "84/84 [==============================] - 6s 74ms/step - loss: 41.0869 - val_loss: 41.4477\n",
      "Epoch 51/1000\n",
      "84/84 [==============================] - 6s 75ms/step - loss: 40.4266 - val_loss: 40.6658\n",
      "Epoch 52/1000\n",
      "84/84 [==============================] - 6s 74ms/step - loss: 40.4686 - val_loss: 41.3987\n",
      "Epoch 53/1000\n",
      "84/84 [==============================] - 6s 75ms/step - loss: 39.7449 - val_loss: 40.1565\n",
      "Epoch 54/1000\n",
      "84/84 [==============================] - 7s 78ms/step - loss: 39.9541 - val_loss: 39.9600\n",
      "Epoch 55/1000\n",
      "84/84 [==============================] - 6s 75ms/step - loss: 39.9177 - val_loss: 40.2525\n",
      "Epoch 56/1000\n",
      "84/84 [==============================] - 6s 76ms/step - loss: 40.1136 - val_loss: 40.8280\n",
      "Epoch 57/1000\n",
      "84/84 [==============================] - 6s 77ms/step - loss: 40.1203 - val_loss: 40.1048\n",
      "Epoch 58/1000\n",
      "84/84 [==============================] - 6s 76ms/step - loss: 39.4937 - val_loss: 39.2217\n",
      "Epoch 59/1000\n",
      "84/84 [==============================] - 6s 75ms/step - loss: 39.4019 - val_loss: 39.2513\n",
      "Epoch 60/1000\n",
      "84/84 [==============================] - 7s 79ms/step - loss: 40.2691 - val_loss: 40.9920\n",
      "Epoch 61/1000\n",
      "84/84 [==============================] - 6s 76ms/step - loss: 39.9801 - val_loss: 39.2880\n",
      "Epoch 62/1000\n",
      "84/84 [==============================] - 7s 81ms/step - loss: 39.5561 - val_loss: 41.2344\n",
      "Epoch 63/1000\n",
      "84/84 [==============================] - 6s 75ms/step - loss: 39.9300 - val_loss: 39.4672\n",
      "Epoch 64/1000\n",
      "84/84 [==============================] - 6s 77ms/step - loss: 39.3874 - val_loss: 39.1006\n",
      "Epoch 65/1000\n",
      "84/84 [==============================] - 6s 77ms/step - loss: 39.6396 - val_loss: 39.9131\n",
      "Epoch 66/1000\n",
      "84/84 [==============================] - 7s 79ms/step - loss: 39.1872 - val_loss: 38.4033\n",
      "Epoch 67/1000\n",
      "84/84 [==============================] - 7s 79ms/step - loss: 39.4831 - val_loss: 42.6391\n",
      "Epoch 68/1000\n",
      "84/84 [==============================] - 6s 75ms/step - loss: 38.9918 - val_loss: 40.7691\n",
      "Epoch 69/1000\n",
      "84/84 [==============================] - 7s 79ms/step - loss: 38.7354 - val_loss: 40.0665\n",
      "Epoch 70/1000\n",
      "84/84 [==============================] - 7s 79ms/step - loss: 38.7727 - val_loss: 39.3232\n",
      "Epoch 71/1000\n",
      "84/84 [==============================] - 7s 78ms/step - loss: 39.2040 - val_loss: 39.5656\n",
      "Epoch 72/1000\n",
      "84/84 [==============================] - 6s 74ms/step - loss: 38.9320 - val_loss: 39.5995\n",
      "Epoch 73/1000\n",
      "84/84 [==============================] - 6s 74ms/step - loss: 38.2098 - val_loss: 38.3526\n",
      "Epoch 74/1000\n",
      "84/84 [==============================] - 6s 75ms/step - loss: 38.2433 - val_loss: 39.4955\n",
      "Epoch 75/1000\n",
      "84/84 [==============================] - 6s 77ms/step - loss: 37.6966 - val_loss: 39.1829\n",
      "Epoch 76/1000\n",
      "84/84 [==============================] - 7s 78ms/step - loss: 37.9809 - val_loss: 38.1152\n",
      "Epoch 77/1000\n",
      "84/84 [==============================] - 7s 79ms/step - loss: 37.8005 - val_loss: 39.5359\n",
      "Epoch 78/1000\n",
      "84/84 [==============================] - 7s 78ms/step - loss: 37.7065 - val_loss: 38.0491\n",
      "Epoch 79/1000\n",
      "84/84 [==============================] - 7s 79ms/step - loss: 37.7448 - val_loss: 37.5146\n",
      "Epoch 80/1000\n",
      "84/84 [==============================] - 6s 76ms/step - loss: 37.9561 - val_loss: 37.3554\n",
      "Epoch 81/1000\n",
      "84/84 [==============================] - 6s 75ms/step - loss: 37.7455 - val_loss: 37.8730\n",
      "Epoch 82/1000\n",
      "84/84 [==============================] - ETA: 0s - loss: 37.6987"
     ]
    }
   ],
   "source": [
    "history = model.fit(x=training_generator,\n",
    "                    validation_data=validation_generator,\n",
    "                    callbacks=[mcp],\n",
    "                    epochs=1000,\n",
    "                    shuffle=False, # shuffling now occurs within the data-loader\n",
    "                    verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd06b616-1cfc-437c-9a18-836bcb218b31",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
