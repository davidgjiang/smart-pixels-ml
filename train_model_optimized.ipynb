{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "24773cdc-4bbe-48c3-9910-8b39c38bfc7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-05 18:17:41.499315: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-05-05 18:17:42.423584: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import datasets, layers, models\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "import keras\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import *\n",
    "from keras.utils import Sequence\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from qkeras import *\n",
    "\n",
    "from keras.utils import Sequence\n",
    "from keras.callbacks import CSVLogger\n",
    "from keras.callbacks import EarlyStopping\n",
    "\n",
    "import os\n",
    "import glob\n",
    "import shutil\n",
    "import random\n",
    "import psutil\n",
    "import random\n",
    "\n",
    "pi = 3.14159265359\n",
    "\n",
    "maxval=1e9\n",
    "minval=1e-9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1ac065e8-fcf2-44a0-8dee-e1e44e605137",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-12 13:26:45.745560: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1747074405.765701 4004372 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1747074405.772097 4004372 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "W0000 00:00:1747074405.787944 4004372 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1747074405.787969 4004372 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1747074405.787972 4004372 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1747074405.787975 4004372 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "2025-05-12 13:26:45.793117: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'tensorflow_probability'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mdataloaders\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mOptimizedDataGenerator\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m OptimizedDataGenerator\n\u001b[0;32m----> 2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mloss\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmodels\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodels\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m\n",
      "File \u001b[0;32m~/smart-pixels-ml/loss.py:2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mtf\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtensorflow_probability\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mtfp\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m# custom loss function\u001b[39;00m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;129m@tf\u001b[39m\u001b[38;5;241m.\u001b[39mfunction\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcustom_loss\u001b[39m(y, p_base, minval\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1e-9\u001b[39m, maxval\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1e9\u001b[39m):\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'tensorflow_probability'"
     ]
    }
   ],
   "source": [
    "from dataloaders.OptimizedDataGenerator import OptimizedDataGenerator\n",
    "from loss import *\n",
    "from models.models import *"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff8a5f7c-8055-4038-a78f-941ee1af8425",
   "metadata": {},
   "source": [
    "#### Set random seed for reproducibility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e2d703cf-790e-41dc-b624-2c078ad07bbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 10\n",
    "tf.random.set_seed(seed)\n",
    "np.random.seed(seed)\n",
    "random.seed(seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "724a4fab-9a72-4728-ac5d-09fbd6f6afd8",
   "metadata": {},
   "source": [
    "#### Scaling Lists for Different Pixel Pitches (dataset_2s):\n",
    "* 100x25x100 um:  [150.0, 37.5, 10.0, 1.22]\n",
    "* 50x25x100 um:   [75.0, 37.5, 10.0, 1.22]\n",
    "* 50x20x100 um:   [75.0, 30.0, 10.0, 1.22]\n",
    "* 50x15x100 um:   [75.0, 22.5, 10.0, 1.22]\n",
    "* 50x12.5x100 um: [75.0, 18.75, 10.0, 1.22]\n",
    "* 50x10x100 um:   [75.0, 15.0, 10.0, 1.22]\n",
    "\n",
    "#### Scaling Lists for Different Pixel Pitches (dataset_3sr):\n",
    "* 100x25x100 um:  [150.0, 37.5, 10.0, 10.0]\n",
    "* 50x25x100 um:   [75.0, 37.5, 10.0, 10.0]\n",
    "* 50x20x100 um:   [75.0, 30.0, 10.0, 10.0]\n",
    "* 50x15x100 um:   [75.0, 22.5, 10.0, 10.0]\n",
    "* 50x12.5x100 um: [75.0, 18.75, 10.0, 10.0]\n",
    "* 50x10x100 um:   [75.0, 15.0, 10.0, 10.0]\n",
    "\n",
    "#### Scaling Lists for Different Pixel Pitches (dataset_3sr, |cot$\\beta$| $\\leq$ 1.5 preselection):\n",
    "* 100x25x100 um:  [150.0, 37.5, 10.0, 1.5], \n",
    "* 50x25x100 um:   [75.0, 37.5, 10.0, 1.5],\n",
    "* 50x20x100 um:   [75.0, 30.0, 10.0, 1.5]\n",
    "* 50x15x100 um:   [75.0, 22.5, 10.0, 1.5]\n",
    "* 50x12.5x100 um: [75.0, 18.75, 10.0, 1.5]\n",
    "* 50x10x100 um:   [75.0, 15.0, 10.0, 1.5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9e1a0184-55a3-4294-b0df-b3067d9bb72f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Directory /data/dajiang/smart-pixels/tfrecords/tfrecords_dataset_3sr_50x12P5_20t_bs5000_cotBeta1P5_quantize_manual_400_1515_2971_train does not exist and cannot be removed.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Files...: 100%|██████████| 60/60 [02:12<00:00,  2.20s/it]\n",
      "Saving batches as TFRecords:   0%|          | 0/137 [00:00<?, ?it/s]2025-04-28 17:00:26.149320: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 3234 MB memory:  -> device: 0, name: NVIDIA A100-SXM4-40GB MIG 1g.5gb, pci bus id: 0000:81:00.0, compute capability: 8.0\n",
      "Saving batches as TFRecords: 100%|██████████| 137/137 [02:18<00:00,  1.01s/it]\n",
      "WARNING:root:Quantization is True in data generator. This may affect model performance.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Directory /data/dajiang/smart-pixels/tfrecords/tfrecords_dataset_3sr_50x12P5_20t_bs5000_cotBeta1P5_quantize_manual_400_1515_2971_val does not exist and cannot be removed.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Files...: 100%|██████████| 20/20 [00:47<00:00,  2.37s/it]\n",
      "Saving batches as TFRecords: 100%|██████████| 45/45 [00:52<00:00,  1.16s/it]\n",
      "WARNING:root:Quantization is True in data generator. This may affect model performance.\n"
     ]
    }
   ],
   "source": [
    "batch_size = 5000\n",
    "val_batch_size = 5000\n",
    "train_file_size = 20\n",
    "val_file_size = 20\n",
    "\n",
    "# Specify what directory to save the tfrecords\n",
    "tfrecords_dir_train = '/data/dajiang/smart-pixels/tfrecords/tfrecords_dataset_2s_50x12P5_2t_train/'\n",
    "tfrecords_dir_val = '/data/dajiang/smart-pixels/tfrecords/tfrecords_dataset_2s_50x12P5_2t_val/'\n",
    "\n",
    "training_generator = OptimizedDataGenerator(\n",
    "    data_directory_path = '/data/dajiang/smart-pixels/dataset_2s/dataset_2s_50x12P5_parquets/unflipped/',\n",
    "    labels_directory_path = '/data/dajiang/smart-pixels/dataset_2s/dataset_2s_50x12P5_parquets/unflipped/',\n",
    "    is_directory_recursive = False,\n",
    "    file_type = 'parquet',\n",
    "    data_format = '3D',\n",
    "    batch_size = batch_size,\n",
    "    file_count = train_file_size,\n",
    "    to_standardize= False,\n",
    "    include_y_local= False,\n",
    "    labels_list = ['x-midplane','y-midplane','cotAlpha','cotBeta'],\n",
    "    scaling_list = [75.0, 18.75, 10.0, 1.22],\n",
    "    input_shape = (2,13,21),\n",
    "    transpose = (0,2,3,1),\n",
    "    files_from_end = True,\n",
    "    shuffle = True,\n",
    "\n",
    "    #load_from_tfrecords_dir = '/data/dajiang/smart-pixels/tfrecords/tfrecords_dataset_2s_50x12P5_2t_train',\n",
    "    tfrecords_dir = tfrecords_dir_train,\n",
    "    use_time_stamps = [0,19], #-1\n",
    "    max_workers = 1, # Don't make this too large (will use up all RAM)\n",
    "    seed = seed,\n",
    "    quantize = True # Quantization ON\n",
    ")\n",
    "\n",
    "validation_generator = OptimizedDataGenerator(\n",
    "    data_directory_path = '/data/dajiang/smart-pixels/dataset_3sr/dataset_3sr_50x12P5_cotBeta1P5_quantize_manual_400_1515_2971_parquets/unflipped/',\n",
    "    labels_directory_path = '/data/dajiang/smart-pixels/dataset_3sr/dataset_3sr_50x12P5_cotBeta1P5_quantize_manual_400_1515_2971_parquets/unflipped/',\n",
    "    is_directory_recursive = False,\n",
    "    file_type = 'parquet',\n",
    "    data_format = '3D',\n",
    "    batch_size = val_batch_size,\n",
    "    file_count = val_file_size,\n",
    "    to_standardize= False,\n",
    "    include_y_local= False,\n",
    "    labels_list = ['x-midplane','y-midplane','cotAlpha','cotBeta'],\n",
    "    scaling_list = [75.0, 18.75, 10.0, 1.5],\n",
    "    input_shape = (20,13,21),\n",
    "    transpose = (0,2,3,1),\n",
    "    files_from_end = False,\n",
    "    shuffle = True,\n",
    "\n",
    "    #load_from_tfrecords_dir = '/data/dajiang/smart-pixels/tfrecords/tfrecords_dataset_2s_50x12P5_2t_val',\n",
    "    tfrecords_dir = tfrecords_dir_val,\n",
    "    use_time_stamps = -1, #-1\n",
    "    max_workers = 1, # Don't make this too large (will use up all RAM)\n",
    "    seed = seed,\n",
    "    quantize = True # Quantization ON\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b9fd3960-c7f1-4d6c-b7e0-0c4c833797d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 13, 21, 20)]      0         \n",
      "                                                                 \n",
      " q_separable_conv2d (QSepar  (None, 11, 19, 5)         285       \n",
      " ableConv2D)                                                     \n",
      "                                                                 \n",
      " q_activation (QActivation)  (None, 11, 19, 5)         0         \n",
      "                                                                 \n",
      " q_conv2d (QConv2D)          (None, 11, 19, 5)         30        \n",
      "                                                                 \n",
      " q_activation_1 (QActivatio  (None, 11, 19, 5)         0         \n",
      " n)                                                              \n",
      "                                                                 \n",
      " average_pooling2d (Average  (None, 3, 6, 5)           0         \n",
      " Pooling2D)                                                      \n",
      "                                                                 \n",
      " q_activation_2 (QActivatio  (None, 3, 6, 5)           0         \n",
      " n)                                                              \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 90)                0         \n",
      "                                                                 \n",
      " q_dense (QDense)            (None, 16)                1456      \n",
      "                                                                 \n",
      " q_activation_3 (QActivatio  (None, 16)                0         \n",
      " n)                                                              \n",
      "                                                                 \n",
      " q_dense_1 (QDense)          (None, 16)                272       \n",
      "                                                                 \n",
      " q_activation_4 (QActivatio  (None, 16)                0         \n",
      " n)                                                              \n",
      "                                                                 \n",
      " q_dense_2 (QDense)          (None, 14)                238       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2281 (8.91 KB)\n",
      "Trainable params: 2281 (8.91 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# compiles model\n",
    "model=CreateModel((13,21,20),n_filters=5,pool_size=3)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "870b8741-98fd-4e1e-bc29-7b9fcbb9b640",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=Adam(learning_rate=0.001), loss=custom_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d3ecb0d-5db2-4610-bd58-e55d06f049a6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model fingerprint: 34c2da80\n",
      "Epoch 1/500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-28 17:07:25.109394: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:432] Loaded cuDNN version 8906\n",
      "2025-04-28 17:07:25.185682: I tensorflow/tsl/platform/default/subprocess.cc:304] Start cannot spawn child process: No such file or directory\n",
      "2025-04-28 17:07:25.473114: I tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:606] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.\n",
      "2025-04-28 17:07:25.482070: I tensorflow/core/util/cuda_solvers.cc:179] Creating GpuSolver handles for stream 0x7fea4d7a7590\n",
      "2025-04-28 17:07:25.523114: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7fd6fd4cb2e0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2025-04-28 17:07:25.523152: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): NVIDIA A100-SXM4-40GB MIG 1g.5gb, Compute Capability 8.0\n",
      "2025-04-28 17:07:25.528678: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:255] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2025-04-28 17:07:25.590743: I tensorflow/tsl/platform/default/subprocess.cc:304] Start cannot spawn child process: No such file or directory\n",
      "2025-04-28 17:07:25.644798: I ./tensorflow/compiler/jit/device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "137/137 [==============================] - 51s 346ms/step - loss: 30816.7715 - val_loss: 11970.6221\n",
      "Epoch 2/500\n",
      "137/137 [==============================] - 30s 217ms/step - loss: 8432.2686 - val_loss: 5177.7031\n",
      "Epoch 3/500\n",
      "137/137 [==============================] - 29s 213ms/step - loss: 4932.2588 - val_loss: 2994.5945\n",
      "Epoch 4/500\n",
      "137/137 [==============================] - 28s 207ms/step - loss: 2049.4468 - val_loss: 859.0220\n",
      "Epoch 5/500\n",
      "137/137 [==============================] - 29s 211ms/step - loss: 643.0757 - val_loss: 590.7726\n",
      "Epoch 6/500\n",
      "137/137 [==============================] - 30s 217ms/step - loss: 259.2581 - val_loss: -274.7324\n",
      "Epoch 7/500\n",
      "137/137 [==============================] - 28s 206ms/step - loss: -130.7471 - val_loss: -732.5890\n",
      "Epoch 8/500\n",
      "137/137 [==============================] - 29s 212ms/step - loss: -736.2985 - val_loss: -888.9834\n",
      "Epoch 9/500\n",
      "137/137 [==============================] - 28s 207ms/step - loss: -1480.1647 - val_loss: -1999.3049\n",
      "Epoch 10/500\n",
      "137/137 [==============================] - 29s 210ms/step - loss: -2573.5859 - val_loss: -3436.0767\n",
      "Epoch 11/500\n",
      "137/137 [==============================] - 30s 222ms/step - loss: -3897.4771 - val_loss: -4707.2524\n",
      "Epoch 12/500\n",
      "137/137 [==============================] - 30s 222ms/step - loss: -5818.9854 - val_loss: -6413.5410\n",
      "Epoch 13/500\n",
      "137/137 [==============================] - 31s 224ms/step - loss: -6961.7017 - val_loss: -7412.8862\n",
      "Epoch 14/500\n",
      "137/137 [==============================] - 31s 225ms/step - loss: -7493.7051 - val_loss: -7441.3809\n",
      "Epoch 15/500\n",
      "137/137 [==============================] - 31s 225ms/step - loss: -7676.2798 - val_loss: -7598.5625\n",
      "Epoch 16/500\n",
      "137/137 [==============================] - 37s 269ms/step - loss: -7510.8330 - val_loss: -8285.3154\n",
      "Epoch 17/500\n",
      "137/137 [==============================] - 39s 289ms/step - loss: -8044.9248 - val_loss: -8198.2949\n",
      "Epoch 18/500\n",
      "137/137 [==============================] - 29s 208ms/step - loss: -5704.2954 - val_loss: -6203.7339\n",
      "Epoch 19/500\n",
      "137/137 [==============================] - 28s 206ms/step - loss: -7906.9849 - val_loss: -8365.6934\n",
      "Epoch 20/500\n",
      "137/137 [==============================] - 29s 211ms/step - loss: -7425.0767 - val_loss: -8382.9717\n",
      "Epoch 21/500\n",
      "137/137 [==============================] - 29s 211ms/step - loss: -8569.6152 - val_loss: -7969.4692\n",
      "Epoch 22/500\n",
      "137/137 [==============================] - 29s 209ms/step - loss: -8938.6074 - val_loss: -8878.9482\n",
      "Epoch 23/500\n",
      "137/137 [==============================] - 29s 209ms/step - loss: -8936.6650 - val_loss: -8685.8213\n",
      "Epoch 24/500\n",
      "137/137 [==============================] - 29s 212ms/step - loss: -9093.0195 - val_loss: -9206.4395\n",
      "Epoch 25/500\n",
      "137/137 [==============================] - 29s 212ms/step - loss: -9172.1006 - val_loss: -8868.9219\n",
      "Epoch 26/500\n",
      "137/137 [==============================] - 29s 212ms/step - loss: -7024.5098 - val_loss: -7119.9194\n",
      "Epoch 27/500\n",
      "137/137 [==============================] - 29s 213ms/step - loss: -8949.0615 - val_loss: -9221.8105\n",
      "Epoch 28/500\n",
      "137/137 [==============================] - 29s 214ms/step - loss: -9379.7520 - val_loss: -9367.1514\n",
      "Epoch 29/500\n",
      "137/137 [==============================] - 29s 212ms/step - loss: -6524.5796 - val_loss: -7949.3286\n",
      "Epoch 30/500\n",
      "137/137 [==============================] - 29s 211ms/step - loss: -7575.5405 - val_loss: -8165.8330\n",
      "Epoch 31/500\n",
      "137/137 [==============================] - 29s 211ms/step - loss: -8663.2119 - val_loss: -9443.4404\n",
      "Epoch 32/500\n",
      "137/137 [==============================] - 37s 266ms/step - loss: -8816.7715 - val_loss: -9336.3906\n",
      "Epoch 33/500\n",
      "137/137 [==============================] - 41s 296ms/step - loss: -8964.6035 - val_loss: -9178.6650\n",
      "Epoch 34/500\n",
      "137/137 [==============================] - 35s 259ms/step - loss: 8687.2783 - val_loss: 775.5936\n",
      "Epoch 35/500\n",
      "137/137 [==============================] - 30s 217ms/step - loss: -6048.0015 - val_loss: -7848.8306\n",
      "Epoch 36/500\n",
      "137/137 [==============================] - 28s 205ms/step - loss: -9963.2793 - val_loss: -10295.4189\n",
      "Epoch 37/500\n",
      "137/137 [==============================] - 28s 207ms/step - loss: -9617.7842 - val_loss: -5724.8135\n",
      "Epoch 38/500\n",
      "137/137 [==============================] - 29s 210ms/step - loss: -8058.2090 - val_loss: -8945.4336\n",
      "Epoch 39/500\n",
      "137/137 [==============================] - 30s 216ms/step - loss: -9536.5127 - val_loss: -10411.8652\n",
      "Epoch 40/500\n",
      "137/137 [==============================] - 29s 213ms/step - loss: -5720.7349 - val_loss: -10014.5176\n",
      "Epoch 41/500\n",
      "137/137 [==============================] - 30s 220ms/step - loss: -7592.3457 - val_loss: -9963.4248\n",
      "Epoch 42/500\n",
      "137/137 [==============================] - 30s 219ms/step - loss: -10179.1748 - val_loss: -9951.8721\n",
      "Epoch 43/500\n",
      "137/137 [==============================] - 29s 215ms/step - loss: -10325.9463 - val_loss: -10544.7549\n",
      "Epoch 44/500\n",
      "137/137 [==============================] - 29s 214ms/step - loss: -10070.2041 - val_loss: -10331.4453\n",
      "Epoch 45/500\n",
      "137/137 [==============================] - 30s 219ms/step - loss: -8862.0898 - val_loss: -8837.0020\n",
      "Epoch 46/500\n",
      "137/137 [==============================] - 29s 215ms/step - loss: -9707.5020 - val_loss: -10973.3916\n",
      "Epoch 47/500\n",
      "137/137 [==============================] - 29s 215ms/step - loss: -10939.2539 - val_loss: -10856.2637\n",
      "Epoch 48/500\n",
      "137/137 [==============================] - 29s 213ms/step - loss: -9962.7217 - val_loss: -9228.2822\n",
      "Epoch 49/500\n",
      "137/137 [==============================] - 29s 211ms/step - loss: -11324.7734 - val_loss: -11335.0488\n",
      "Epoch 50/500\n",
      "137/137 [==============================] - 29s 212ms/step - loss: -10927.6592 - val_loss: -10722.4668\n",
      "Epoch 51/500\n",
      "137/137 [==============================] - 29s 215ms/step - loss: -10839.2129 - val_loss: -11303.9600\n",
      "Epoch 52/500\n",
      "137/137 [==============================] - 29s 211ms/step - loss: -7901.0000 - val_loss: -10222.6582\n",
      "Epoch 53/500\n",
      "137/137 [==============================] - 29s 214ms/step - loss: -10513.6543 - val_loss: -11208.0830\n",
      "Epoch 54/500\n",
      "137/137 [==============================] - 30s 217ms/step - loss: -10783.0596 - val_loss: -10624.9404\n",
      "Epoch 55/500\n",
      "137/137 [==============================] - 28s 208ms/step - loss: -10548.5654 - val_loss: -10996.1143\n",
      "Epoch 56/500\n",
      "137/137 [==============================] - 28s 205ms/step - loss: -10448.0361 - val_loss: -11173.7822\n",
      "Epoch 57/500\n",
      "137/137 [==============================] - 29s 213ms/step - loss: -10536.9062 - val_loss: -10220.4414\n",
      "Epoch 58/500\n",
      "137/137 [==============================] - 29s 214ms/step - loss: -10584.8369 - val_loss: -10676.9883\n",
      "Epoch 59/500\n",
      "137/137 [==============================] - 27s 199ms/step - loss: -10570.9746 - val_loss: -10784.6699\n",
      "Epoch 60/500\n",
      "137/137 [==============================] - 29s 208ms/step - loss: -11317.0654 - val_loss: -11053.4297\n",
      "Epoch 61/500\n",
      "137/137 [==============================] - 29s 214ms/step - loss: -11132.5635 - val_loss: -11488.4795\n",
      "Epoch 62/500\n",
      "137/137 [==============================] - 28s 207ms/step - loss: -11006.1914 - val_loss: -11292.8955\n",
      "Epoch 63/500\n",
      "137/137 [==============================] - 28s 205ms/step - loss: -11522.0742 - val_loss: -12168.8721\n",
      "Epoch 64/500\n",
      "137/137 [==============================] - 28s 206ms/step - loss: -11657.9521 - val_loss: -11372.7373\n",
      "Epoch 65/500\n",
      "137/137 [==============================] - 29s 208ms/step - loss: -11520.6729 - val_loss: -11851.8174\n",
      "Epoch 66/500\n",
      "126/137 [==========================>...] - ETA: 1s - loss: -11788.2422"
     ]
    }
   ],
   "source": [
    "# training\n",
    "pitch = '50x12P5'\n",
    "fingerprint = '%08x' % random.randrange(16**8)\n",
    "base_dir = '/home/dajiang/smart-pixels-ml/weights/weights_7pitches/dataset_3sr_cotBeta1P5_quantize_manual_400_1515_2971_weights/'\n",
    "weights_dir = base_dir + 'weights-{}-bs{}-{}-checkpoints'.format(pitch, batch_size, fingerprint)\n",
    "\n",
    "# create output directories\n",
    "if os.path.isdir(base_dir):\n",
    "    os.mkdir(weights_dir)\n",
    "else:\n",
    "    os.mkdir(base_dir)\n",
    "    os.mkdir(weights_dir)\n",
    "    \n",
    "checkpoint_filepath = weights_dir + '/weights.{epoch:02d}-t{loss:.2f}-v{val_loss:.2f}.hdf5'\n",
    "mcp = tf.keras.callbacks.ModelCheckpoint(\n",
    "    filepath=checkpoint_filepath,\n",
    "    save_weights_only=True,\n",
    "    monitor='val_loss',\n",
    "    save_best_only=False,\n",
    ")\n",
    "\n",
    "print('Model fingerprint: {}'.format(fingerprint))\n",
    "\n",
    "history = model.fit(x=training_generator,\n",
    "                    validation_data=validation_generator,\n",
    "                    callbacks=[mcp],\n",
    "                    epochs=500,\n",
    "                    shuffle=False, # shuffling now occurs within the data-loader\n",
    "                    verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19df6602-80a7-4b58-ae21-73e46bc89d6c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
