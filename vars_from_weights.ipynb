{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e585c8a2-b0fe-485f-b329-33006fbb61be",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-30 17:08:23.870919: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-06-30 17:08:24.772395: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.optimizers import Adam\n",
    "from keras.utils import Sequence\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "pi = 3.14159265359\n",
    "\n",
    "maxval=1e9\n",
    "minval=1e-9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "541b807f-a778-43f9-898e-5d86b73b6a40",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataloaders.OptimizedDataGenerator_v2 import OptimizedDataGenerator\n",
    "from models import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f3fbdfaa-2b97-43d1-81cb-a7f96f0de130",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-30 17:08:26.466029: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 648 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 2080 Ti, pci bus id: 0000:b2:00.0, compute capability: 7.5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 16, 16, 20)]      0         \n",
      "                                                                 \n",
      " q_separable_conv2d (QSepar  (None, 14, 14, 5)         285       \n",
      " ableConv2D)                                                     \n",
      "                                                                 \n",
      " q_activation (QActivation)  (None, 14, 14, 5)         0         \n",
      "                                                                 \n",
      " q_conv2d (QConv2D)          (None, 14, 14, 5)         30        \n",
      "                                                                 \n",
      " q_activation_1 (QActivatio  (None, 14, 14, 5)         0         \n",
      " n)                                                              \n",
      "                                                                 \n",
      " average_pooling2d (Average  (None, 4, 4, 5)           0         \n",
      " Pooling2D)                                                      \n",
      "                                                                 \n",
      " q_activation_2 (QActivatio  (None, 4, 4, 5)           0         \n",
      " n)                                                              \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 80)                0         \n",
      "                                                                 \n",
      " q_dense (QDense)            (None, 16)                1296      \n",
      "                                                                 \n",
      " q_activation_3 (QActivatio  (None, 16)                0         \n",
      " n)                                                              \n",
      "                                                                 \n",
      " q_dense_1 (QDense)          (None, 16)                272       \n",
      "                                                                 \n",
      " q_activation_4 (QActivatio  (None, 16)                0         \n",
      " n)                                                              \n",
      "                                                                 \n",
      " q_dense_2 (QDense)          (None, 14)                238       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2121 (8.29 KB)\n",
      "Trainable params: 2121 (8.29 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model=CreateModel((16,16,20),n_filters=5,pool_size=3)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e9c498e2-3971-471e-a2b6-9b44385cfd24",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best model: weights.971-t-29391.59-v-30412.73.hdf5\n"
     ]
    }
   ],
   "source": [
    "# get best weights file\n",
    "pitch = '50x12P5'\n",
    "batch_size = 5000\n",
    "fingerprint = '34c2da80'\n",
    "timeslices = 20\n",
    "files = os.listdir('/data/dajiang/smart-pixels/weights/dataset_3src_16x16_weights/weights-{}-bs{}-{}-{}t-nonquantized_input-checkpoints'.format(pitch, batch_size, fingerprint, timeslices))\n",
    "\n",
    "vlosses = [float(f.split(\"-v\")[1].split(\".hdf5\")[0]) for f in files]\n",
    "bestfile = files[np.argmin(vlosses)]\n",
    "model.load_weights('/data/dajiang/smart-pixels/weights/dataset_3src_16x16_weights/weights-{}-bs{}-{}-{}t-nonquantized_input-checkpoints/'.format(pitch, batch_size, fingerprint, timeslices)+bestfile)\n",
    "\n",
    "print('Best model: {}'.format(bestfile))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "db70942f-f779-4659-ab03-578201ae8412",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Quantization is True in data generator. This may affect model performance.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading metadata from /data/dajiang/smart-pixels/dataset_3sr/shuffled/dataset_3sr_16x16_50x12P5_parquets/contained/TFR_files/20t/TFR_val/metadata.json\n"
     ]
    }
   ],
   "source": [
    "# load in the test set\n",
    "test_generator = OptimizedDataGenerator(\n",
    "    load_from_tfrecords_dir = '/data/dajiang/smart-pixels/dataset_3sr/shuffled/dataset_3sr_16x16_{}_parquets/contained/TFR_files/{}t/TFR_val'.format(pitch, timeslices),\n",
    "    quantize = True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "10f180d0-98d6-49d2-bd95-c83231e0ab13",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-30 17:08:39.954991: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:432] Loaded cuDNN version 8906\n",
      "2025-06-30 17:08:40.062794: I tensorflow/tsl/platform/default/subprocess.cc:304] Start cannot spawn child process: No such file or directory\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 1/21 [>.............................] - ETA: 21s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-30 17:08:40.157259: W tensorflow/tsl/framework/bfc_allocator.cc:296] Allocator (GPU_0_bfc) ran out of memory trying to allocate 90.77MiB with freed_by_count=0. The caller indicates that this is not a failure, but this may mean that there could be performance gains if more memory were available.\n",
      "2025-06-30 17:08:40.160107: W tensorflow/tsl/framework/bfc_allocator.cc:296] Allocator (GPU_0_bfc) ran out of memory trying to allocate 242.99MiB with freed_by_count=0. The caller indicates that this is not a failure, but this may mean that there could be performance gains if more memory were available.\n",
      "2025-06-30 17:08:40.162204: W tensorflow/tsl/framework/bfc_allocator.cc:296] Allocator (GPU_0_bfc) ran out of memory trying to allocate 235.95MiB with freed_by_count=0. The caller indicates that this is not a failure, but this may mean that there could be performance gains if more memory were available.\n",
      "2025-06-30 17:08:40.178265: W tensorflow/tsl/framework/bfc_allocator.cc:296] Allocator (GPU_0_bfc) ran out of memory trying to allocate 106.79MiB with freed_by_count=0. The caller indicates that this is not a failure, but this may mean that there could be performance gains if more memory were available.\n",
      "2025-06-30 17:08:40.179018: W tensorflow/tsl/framework/bfc_allocator.cc:296] Allocator (GPU_0_bfc) ran out of memory trying to allocate 70.99MiB with freed_by_count=0. The caller indicates that this is not a failure, but this may mean that there could be performance gains if more memory were available.\n",
      "2025-06-30 17:08:50.163699: W tensorflow/tsl/framework/bfc_allocator.cc:485] Allocator (GPU_0_bfc) ran out of memory trying to allocate 95.66MiB (rounded to 100311040)requested by op AddV2\n",
      "If the cause is memory fragmentation maybe the environment variable 'TF_GPU_ALLOCATOR=cuda_malloc_async' will improve the situation. \n",
      "Current allocation summary follows.\n",
      "Current allocation summary follows.\n",
      "2025-06-30 17:08:50.163783: I tensorflow/tsl/framework/bfc_allocator.cc:1039] BFCAllocator dump for GPU_0_bfc\n",
      "2025-06-30 17:08:50.163819: I tensorflow/tsl/framework/bfc_allocator.cc:1046] Bin (256): \tTotal Chunks: 55, Chunks in use: 50. 13.8KiB allocated for chunks. 12.5KiB in use in bin. 820B client-requested in use in bin.\n",
      "2025-06-30 17:08:50.163848: I tensorflow/tsl/framework/bfc_allocator.cc:1046] Bin (512): \tTotal Chunks: 6, Chunks in use: 4. 4.0KiB allocated for chunks. 2.8KiB in use in bin. 2.2KiB client-requested in use in bin.\n",
      "2025-06-30 17:08:50.163874: I tensorflow/tsl/framework/bfc_allocator.cc:1046] Bin (1024): \tTotal Chunks: 7, Chunks in use: 5. 7.5KiB allocated for chunks. 5.5KiB in use in bin. 4.8KiB client-requested in use in bin.\n",
      "2025-06-30 17:08:50.163900: I tensorflow/tsl/framework/bfc_allocator.cc:1046] Bin (2048): \tTotal Chunks: 1, Chunks in use: 0. 3.5KiB allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2025-06-30 17:08:50.163928: I tensorflow/tsl/framework/bfc_allocator.cc:1046] Bin (4096): \tTotal Chunks: 3, Chunks in use: 2. 17.2KiB allocated for chunks. 10.0KiB in use in bin. 10.0KiB client-requested in use in bin.\n",
      "2025-06-30 17:08:50.163959: I tensorflow/tsl/framework/bfc_allocator.cc:1046] Bin (8192): \tTotal Chunks: 1, Chunks in use: 0. 10.2KiB allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2025-06-30 17:08:50.163966: I tensorflow/tsl/framework/bfc_allocator.cc:1046] Bin (16384): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2025-06-30 17:08:50.163974: I tensorflow/tsl/framework/bfc_allocator.cc:1046] Bin (32768): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2025-06-30 17:08:50.163982: I tensorflow/tsl/framework/bfc_allocator.cc:1046] Bin (65536): \tTotal Chunks: 2, Chunks in use: 2. 155.0KiB allocated for chunks. 155.0KiB in use in bin. 154.7KiB client-requested in use in bin.\n",
      "2025-06-30 17:08:50.163990: I tensorflow/tsl/framework/bfc_allocator.cc:1046] Bin (131072): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2025-06-30 17:08:50.164014: I tensorflow/tsl/framework/bfc_allocator.cc:1046] Bin (262144): \tTotal Chunks: 1, Chunks in use: 1. 312.5KiB allocated for chunks. 312.5KiB in use in bin. 273.4KiB client-requested in use in bin.\n",
      "2025-06-30 17:08:50.164022: I tensorflow/tsl/framework/bfc_allocator.cc:1046] Bin (524288): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2025-06-30 17:08:50.164030: I tensorflow/tsl/framework/bfc_allocator.cc:1046] Bin (1048576): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2025-06-30 17:08:50.164037: I tensorflow/tsl/framework/bfc_allocator.cc:1046] Bin (2097152): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2025-06-30 17:08:50.164045: I tensorflow/tsl/framework/bfc_allocator.cc:1046] Bin (4194304): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2025-06-30 17:08:50.164052: I tensorflow/tsl/framework/bfc_allocator.cc:1046] Bin (8388608): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2025-06-30 17:08:50.164060: I tensorflow/tsl/framework/bfc_allocator.cc:1046] Bin (16777216): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2025-06-30 17:08:50.164067: I tensorflow/tsl/framework/bfc_allocator.cc:1046] Bin (33554432): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2025-06-30 17:08:50.164076: I tensorflow/tsl/framework/bfc_allocator.cc:1046] Bin (67108864): \tTotal Chunks: 7, Chunks in use: 5. 647.55MiB allocated for chunks. 488.28MiB in use in bin. 480.31MiB client-requested in use in bin.\n",
      "2025-06-30 17:08:50.164084: I tensorflow/tsl/framework/bfc_allocator.cc:1046] Bin (134217728): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2025-06-30 17:08:50.164094: I tensorflow/tsl/framework/bfc_allocator.cc:1046] Bin (268435456): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2025-06-30 17:08:50.164102: I tensorflow/tsl/framework/bfc_allocator.cc:1062] Bin for 95.66MiB was 64.00MiB, Chunk State: \n",
      "2025-06-30 17:08:50.164114: I tensorflow/tsl/framework/bfc_allocator.cc:1068]   Size: 69.07MiB | Requested Size: 100B | in_use: 0 | bin_num: 18, prev:   Size: 256B | Requested Size: 100B | in_use: 1 | bin_num: -1, next:   Size: 76.8KiB | Requested Size: 76.5KiB | in_use: 1 | bin_num: -1\n",
      "2025-06-30 17:08:50.164124: I tensorflow/tsl/framework/bfc_allocator.cc:1068]   Size: 90.20MiB | Requested Size: 34.69MiB | in_use: 0 | bin_num: 18, prev:   Size: 76.8KiB | Requested Size: 76.5KiB | in_use: 1 | bin_num: -1\n",
      "2025-06-30 17:08:50.164131: I tensorflow/tsl/framework/bfc_allocator.cc:1075] Next region of size 679542784\n",
      "2025-06-30 17:08:50.164139: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fb466000000 of size 1280 next 1\n",
      "2025-06-30 17:08:50.164148: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fb466000500 of size 256 next 2\n",
      "2025-06-30 17:08:50.164155: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fb466000600 of size 256 next 3\n",
      "2025-06-30 17:08:50.164162: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fb466000700 of size 256 next 4\n",
      "2025-06-30 17:08:50.164168: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fb466000800 of size 256 next 5\n",
      "2025-06-30 17:08:50.164175: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fb466000900 of size 768 next 10\n",
      "2025-06-30 17:08:50.164182: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fb466000c00 of size 256 next 11\n",
      "2025-06-30 17:08:50.164189: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fb466000d00 of size 256 next 7\n",
      "2025-06-30 17:08:50.164196: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fb466000e00 of size 256 next 16\n",
      "2025-06-30 17:08:50.164202: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fb466000f00 of size 256 next 13\n",
      "2025-06-30 17:08:50.164209: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fb466001000 of size 256 next 14\n",
      "2025-06-30 17:08:50.164216: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fb466001100 of size 256 next 6\n",
      "2025-06-30 17:08:50.164223: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fb466001200 of size 256 next 9\n",
      "2025-06-30 17:08:50.164230: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fb466001300 of size 256 next 8\n",
      "2025-06-30 17:08:50.164236: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fb466001400 of size 256 next 27\n",
      "2025-06-30 17:08:50.164243: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fb466001500 of size 256 next 18\n",
      "2025-06-30 17:08:50.164250: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fb466001600 of size 256 next 15\n",
      "2025-06-30 17:08:50.164257: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fb466001700 of size 1024 next 20\n",
      "2025-06-30 17:08:50.164264: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fb466001b00 of size 256 next 34\n",
      "2025-06-30 17:08:50.164271: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fb466001c00 of size 256 next 37\n",
      "2025-06-30 17:08:50.164278: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fb466001d00 of size 256 next 35\n",
      "2025-06-30 17:08:50.164294: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fb466001e00 of size 256 next 36\n",
      "2025-06-30 17:08:50.164301: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fb466001f00 of size 256 next 28\n",
      "2025-06-30 17:08:50.164308: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fb466002000 of size 256 next 29\n",
      "2025-06-30 17:08:50.164315: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fb466002100 of size 256 next 32\n",
      "2025-06-30 17:08:50.164322: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fb466002200 of size 256 next 33\n",
      "2025-06-30 17:08:50.164328: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fb466002300 of size 256 next 38\n",
      "2025-06-30 17:08:50.164335: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fb466002400 of size 256 next 39\n",
      "2025-06-30 17:08:50.164342: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fb466002500 of size 256 next 40\n",
      "2025-06-30 17:08:50.164349: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fb466002600 of size 256 next 41\n",
      "2025-06-30 17:08:50.164355: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fb466002700 of size 256 next 42\n",
      "2025-06-30 17:08:50.164362: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fb466002800 of size 256 next 43\n",
      "2025-06-30 17:08:50.164369: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fb466002900 of size 256 next 44\n",
      "2025-06-30 17:08:50.164376: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fb466002a00 of size 256 next 45\n",
      "2025-06-30 17:08:50.164383: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fb466002b00 of size 256 next 21\n",
      "2025-06-30 17:08:50.164390: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fb466002c00 of size 256 next 12\n",
      "2025-06-30 17:08:50.164396: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fb466002d00 of size 1280 next 24\n",
      "2025-06-30 17:08:50.164403: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fb466003200 of size 256 next 23\n",
      "2025-06-30 17:08:50.164410: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fb466003300 of size 256 next 25\n",
      "2025-06-30 17:08:50.164417: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fb466003400 of size 256 next 30\n",
      "2025-06-30 17:08:50.164424: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fb466003500 of size 256 next 31\n",
      "2025-06-30 17:08:50.164431: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fb466003600 of size 256 next 26\n",
      "2025-06-30 17:08:50.164437: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fb466003700 of size 256 next 22\n",
      "2025-06-30 17:08:50.164444: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fb466003800 of size 768 next 19\n",
      "2025-06-30 17:08:50.164451: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fb466003b00 of size 5120 next 17\n",
      "2025-06-30 17:08:50.164458: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fb466004f00 of size 256 next 46\n",
      "2025-06-30 17:08:50.164465: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fb466005000 of size 256 next 47\n",
      "2025-06-30 17:08:50.164472: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fb466005100 of size 256 next 48\n",
      "2025-06-30 17:08:50.164480: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fb466005200 of size 256 next 73\n",
      "2025-06-30 17:08:50.164487: I tensorflow/tsl/framework/bfc_allocator.cc:1095] Free  at 7fb466005300 of size 10496 next 62\n",
      "2025-06-30 17:08:50.164494: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fb466007c00 of size 256 next 63\n",
      "2025-06-30 17:08:50.164501: I tensorflow/tsl/framework/bfc_allocator.cc:1095] Free  at 7fb466007d00 of size 3584 next 68\n",
      "2025-06-30 17:08:50.164508: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fb466008b00 of size 256 next 66\n",
      "2025-06-30 17:08:50.164519: I tensorflow/tsl/framework/bfc_allocator.cc:1095] Free  at 7fb466008c00 of size 256 next 69\n",
      "2025-06-30 17:08:50.164531: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fb466008d00 of size 256 next 79\n",
      "2025-06-30 17:08:50.164543: I tensorflow/tsl/framework/bfc_allocator.cc:1095] Free  at 7fb466008e00 of size 256 next 75\n",
      "2025-06-30 17:08:50.164551: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fb466008f00 of size 512 next 76\n",
      "2025-06-30 17:08:50.164558: I tensorflow/tsl/framework/bfc_allocator.cc:1095] Free  at 7fb466009100 of size 512 next 64\n",
      "2025-06-30 17:08:50.164565: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fb466009300 of size 256 next 70\n",
      "2025-06-30 17:08:50.164573: I tensorflow/tsl/framework/bfc_allocator.cc:1095] Free  at 7fb466009400 of size 256 next 51\n",
      "2025-06-30 17:08:50.164579: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fb466009500 of size 5120 next 50\n",
      "2025-06-30 17:08:50.164586: I tensorflow/tsl/framework/bfc_allocator.cc:1095] Free  at 7fb46600a900 of size 7424 next 80\n",
      "2025-06-30 17:08:50.164594: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fb46600c600 of size 102400000 next 58\n",
      "2025-06-30 17:08:50.164601: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fb46c1b4600 of size 80128 next 81\n",
      "2025-06-30 17:08:50.164609: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fb46c1c7f00 of size 100311040 next 56\n",
      "2025-06-30 17:08:50.164616: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fb472171f00 of size 100311040 next 52\n",
      "2025-06-30 17:08:50.164623: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fb47811bf00 of size 106577920 next 55\n",
      "2025-06-30 17:08:50.164630: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fb47e6bff00 of size 102400000 next 54\n",
      "2025-06-30 17:08:50.164637: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fb484867f00 of size 320000 next 65\n",
      "2025-06-30 17:08:50.164644: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fb4848b6100 of size 768 next 49\n",
      "2025-06-30 17:08:50.164655: I tensorflow/tsl/framework/bfc_allocator.cc:1095] Free  at 7fb4848b6400 of size 768 next 82\n",
      "2025-06-30 17:08:50.164666: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fb4848b6700 of size 1024 next 83\n",
      "2025-06-30 17:08:50.164677: I tensorflow/tsl/framework/bfc_allocator.cc:1095] Free  at 7fb4848b6b00 of size 1024 next 84\n",
      "2025-06-30 17:08:50.164690: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fb4848b6f00 of size 256 next 85\n",
      "2025-06-30 17:08:50.164701: I tensorflow/tsl/framework/bfc_allocator.cc:1095] Free  at 7fb4848b7000 of size 256 next 86\n",
      "2025-06-30 17:08:50.164711: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fb4848b7100 of size 256 next 87\n",
      "2025-06-30 17:08:50.164721: I tensorflow/tsl/framework/bfc_allocator.cc:1095] Free  at 7fb4848b7200 of size 256 next 88\n",
      "2025-06-30 17:08:50.164733: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fb4848b7300 of size 1024 next 89\n",
      "2025-06-30 17:08:50.164745: I tensorflow/tsl/framework/bfc_allocator.cc:1095] Free  at 7fb4848b7700 of size 1024 next 90\n",
      "2025-06-30 17:08:50.164758: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fb4848b7b00 of size 256 next 91\n",
      "2025-06-30 17:08:50.164772: I tensorflow/tsl/framework/bfc_allocator.cc:1095] Free  at 7fb4848b7c00 of size 72429056 next 57\n",
      "2025-06-30 17:08:50.164785: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fb488dcaa00 of size 78592 next 53\n",
      "2025-06-30 17:08:50.164798: I tensorflow/tsl/framework/bfc_allocator.cc:1095] Free  at 7fb488dddd00 of size 94577408 next 18446744073709551615\n",
      "2025-06-30 17:08:50.164811: I tensorflow/tsl/framework/bfc_allocator.cc:1100]      Summary of in-use Chunks by size: \n",
      "2025-06-30 17:08:50.164826: I tensorflow/tsl/framework/bfc_allocator.cc:1103] 50 Chunks of size 256 totalling 12.5KiB\n",
      "2025-06-30 17:08:50.164840: I tensorflow/tsl/framework/bfc_allocator.cc:1103] 1 Chunks of size 512 totalling 512B\n",
      "2025-06-30 17:08:50.164853: I tensorflow/tsl/framework/bfc_allocator.cc:1103] 3 Chunks of size 768 totalling 2.2KiB\n",
      "2025-06-30 17:08:50.164868: I tensorflow/tsl/framework/bfc_allocator.cc:1103] 3 Chunks of size 1024 totalling 3.0KiB\n",
      "2025-06-30 17:08:50.164881: I tensorflow/tsl/framework/bfc_allocator.cc:1103] 2 Chunks of size 1280 totalling 2.5KiB\n",
      "2025-06-30 17:08:50.164894: I tensorflow/tsl/framework/bfc_allocator.cc:1103] 2 Chunks of size 5120 totalling 10.0KiB\n",
      "2025-06-30 17:08:50.164907: I tensorflow/tsl/framework/bfc_allocator.cc:1103] 1 Chunks of size 78592 totalling 76.8KiB\n",
      "2025-06-30 17:08:50.164919: I tensorflow/tsl/framework/bfc_allocator.cc:1103] 1 Chunks of size 80128 totalling 78.2KiB\n",
      "2025-06-30 17:08:50.164929: I tensorflow/tsl/framework/bfc_allocator.cc:1103] 1 Chunks of size 320000 totalling 312.5KiB\n",
      "2025-06-30 17:08:50.164942: I tensorflow/tsl/framework/bfc_allocator.cc:1103] 2 Chunks of size 100311040 totalling 191.33MiB\n",
      "2025-06-30 17:08:50.164956: I tensorflow/tsl/framework/bfc_allocator.cc:1103] 2 Chunks of size 102400000 totalling 195.31MiB\n",
      "2025-06-30 17:08:50.164971: I tensorflow/tsl/framework/bfc_allocator.cc:1103] 1 Chunks of size 106577920 totalling 101.64MiB\n",
      "2025-06-30 17:08:50.164986: I tensorflow/tsl/framework/bfc_allocator.cc:1107] Sum Total of in-use chunks: 488.77MiB\n",
      "2025-06-30 17:08:50.165000: I tensorflow/tsl/framework/bfc_allocator.cc:1109] Total bytes in pool: 679542784 memory_limit_: 679542784 available bytes: 0 curr_region_allocation_bytes_: 1359085568\n",
      "2025-06-30 17:08:50.165019: I tensorflow/tsl/framework/bfc_allocator.cc:1114] Stats: \n",
      "Limit:                       679542784\n",
      "InUse:                       512510208\n",
      "MaxInUse:                    645966336\n",
      "NumAllocs:                         331\n",
      "MaxAllocSize:                167411968\n",
      "Reserved:                            0\n",
      "PeakReserved:                        0\n",
      "LargestFreeBlock:                    0\n",
      "\n",
      "2025-06-30 17:08:50.165036: W tensorflow/tsl/framework/bfc_allocator.cc:497] ****************************************************************************__________*_____________\n",
      "2025-06-30 17:08:50.165057: W tensorflow/core/framework/op_kernel.cc:1816] RESOURCE_EXHAUSTED: failed to allocate memory\n",
      "2025-06-30 17:08:50.167790: W tensorflow/core/framework/op_kernel.cc:1816] UNKNOWN: ResourceExhaustedError: {{function_node __wrapped__AddV2_device_/job:localhost/replica:0/task:0/device:GPU:0}} failed to allocate memory [Op:AddV2] name: \n",
      "Traceback (most recent call last):\n",
      "\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/tensorflow/python/ops/script_ops.py\", line 268, in __call__\n",
      "    ret = func(*args)\n",
      "\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/tensorflow/python/autograph/impl/api.py\", line 643, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/tensorflow/python/data/ops/from_generator_op.py\", line 198, in generator_py_func\n",
      "    values = next(generator_state.get_iterator(iterator_id))\n",
      "\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/keras/src/engine/data_adapter.py\", line 917, in wrapped_generator\n",
      "    for data in generator_fn():\n",
      "\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/keras/src/engine/data_adapter.py\", line 1064, in generator_fn\n",
      "    yield x[i]\n",
      "\n",
      "  File \"/home/dajiang/smart-pixels-ml/dataloaders/OptimizedDataGenerator_v2.py\", line 587, in __getitem__\n",
      "    X_batch = QKeras_data_prep_quantizer(X_batch, bits=4, int_bits=0, alpha=1)\n",
      "\n",
      "  File \"/home/dajiang/smart-pixels-ml/dataloaders/OptimizedDataGenerator_v2.py\", line 37, in QKeras_data_prep_quantizer\n",
      "    return quantizer(data)\n",
      "\n",
      "  File \"/home/dajiang/.local/lib/python3.8/site-packages/qkeras/quantizers.py\", line 634, in __call__\n",
      "    _round_through(p, self.use_stochastic_rounding, precision=1.0),\n",
      "\n",
      "  File \"/home/dajiang/.local/lib/python3.8/site-packages/qkeras/quantizers.py\", line 326, in _round_through\n",
      "    output = x + tf.stop_gradient(-x + tf.round(x))\n",
      "\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/tensorflow/python/util/traceback_utils.py\", line 153, in error_handler\n",
      "    raise e.with_traceback(filtered_tb) from None\n",
      "\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/tensorflow/python/framework/ops.py\", line 6656, in raise_from_not_ok_status\n",
      "    raise core._status_to_exception(e) from None  # pylint: disable=protected-access\n",
      "\n",
      "tensorflow.python.framework.errors_impl.ResourceExhaustedError: {{function_node __wrapped__AddV2_device_/job:localhost/replica:0/task:0/device:GPU:0}} failed to allocate memory [Op:AddV2] name: \n",
      "\n",
      "\n",
      "2025-06-30 17:08:50.168058: I tensorflow/core/framework/local_rendezvous.cc:405] Local rendezvous recv item cancelled. Key hash: 9455265495888339174\n"
     ]
    },
    {
     "ename": "UnknownError",
     "evalue": "Graph execution error:\n\n2 root error(s) found.\n  (0) UNKNOWN:  ResourceExhaustedError: {{function_node __wrapped__AddV2_device_/job:localhost/replica:0/task:0/device:GPU:0}} failed to allocate memory [Op:AddV2] name: \nTraceback (most recent call last):\n\n  File \"/usr/local/lib/python3.8/dist-packages/tensorflow/python/ops/script_ops.py\", line 268, in __call__\n    ret = func(*args)\n\n  File \"/usr/local/lib/python3.8/dist-packages/tensorflow/python/autograph/impl/api.py\", line 643, in wrapper\n    return func(*args, **kwargs)\n\n  File \"/usr/local/lib/python3.8/dist-packages/tensorflow/python/data/ops/from_generator_op.py\", line 198, in generator_py_func\n    values = next(generator_state.get_iterator(iterator_id))\n\n  File \"/usr/local/lib/python3.8/dist-packages/keras/src/engine/data_adapter.py\", line 917, in wrapped_generator\n    for data in generator_fn():\n\n  File \"/usr/local/lib/python3.8/dist-packages/keras/src/engine/data_adapter.py\", line 1064, in generator_fn\n    yield x[i]\n\n  File \"/home/dajiang/smart-pixels-ml/dataloaders/OptimizedDataGenerator_v2.py\", line 587, in __getitem__\n    X_batch = QKeras_data_prep_quantizer(X_batch, bits=4, int_bits=0, alpha=1)\n\n  File \"/home/dajiang/smart-pixels-ml/dataloaders/OptimizedDataGenerator_v2.py\", line 37, in QKeras_data_prep_quantizer\n    return quantizer(data)\n\n  File \"/home/dajiang/.local/lib/python3.8/site-packages/qkeras/quantizers.py\", line 634, in __call__\n    _round_through(p, self.use_stochastic_rounding, precision=1.0),\n\n  File \"/home/dajiang/.local/lib/python3.8/site-packages/qkeras/quantizers.py\", line 326, in _round_through\n    output = x + tf.stop_gradient(-x + tf.round(x))\n\n  File \"/usr/local/lib/python3.8/dist-packages/tensorflow/python/util/traceback_utils.py\", line 153, in error_handler\n    raise e.with_traceback(filtered_tb) from None\n\n  File \"/usr/local/lib/python3.8/dist-packages/tensorflow/python/framework/ops.py\", line 6656, in raise_from_not_ok_status\n    raise core._status_to_exception(e) from None  # pylint: disable=protected-access\n\ntensorflow.python.framework.errors_impl.ResourceExhaustedError: {{function_node __wrapped__AddV2_device_/job:localhost/replica:0/task:0/device:GPU:0}} failed to allocate memory [Op:AddV2] name: \n\n\n\t [[{{node PyFunc}}]]\n\t [[IteratorGetNext]]\n\t [[IteratorGetNext/_2]]\n  (1) UNKNOWN:  ResourceExhaustedError: {{function_node __wrapped__AddV2_device_/job:localhost/replica:0/task:0/device:GPU:0}} failed to allocate memory [Op:AddV2] name: \nTraceback (most recent call last):\n\n  File \"/usr/local/lib/python3.8/dist-packages/tensorflow/python/ops/script_ops.py\", line 268, in __call__\n    ret = func(*args)\n\n  File \"/usr/local/lib/python3.8/dist-packages/tensorflow/python/autograph/impl/api.py\", line 643, in wrapper\n    return func(*args, **kwargs)\n\n  File \"/usr/local/lib/python3.8/dist-packages/tensorflow/python/data/ops/from_generator_op.py\", line 198, in generator_py_func\n    values = next(generator_state.get_iterator(iterator_id))\n\n  File \"/usr/local/lib/python3.8/dist-packages/keras/src/engine/data_adapter.py\", line 917, in wrapped_generator\n    for data in generator_fn():\n\n  File \"/usr/local/lib/python3.8/dist-packages/keras/src/engine/data_adapter.py\", line 1064, in generator_fn\n    yield x[i]\n\n  File \"/home/dajiang/smart-pixels-ml/dataloaders/OptimizedDataGenerator_v2.py\", line 587, in __getitem__\n    X_batch = QKeras_data_prep_quantizer(X_batch, bits=4, int_bits=0, alpha=1)\n\n  File \"/home/dajiang/smart-pixels-ml/dataloaders/OptimizedDataGenerator_v2.py\", line 37, in QKeras_data_prep_quantizer\n    return quantizer(data)\n\n  File \"/home/dajiang/.local/lib/python3.8/site-packages/qkeras/quantizers.py\", line 634, in __call__\n    _round_through(p, self.use_stochastic_rounding, precision=1.0),\n\n  File \"/home/dajiang/.local/lib/python3.8/site-packages/qkeras/quantizers.py\", line 326, in _round_through\n    output = x + tf.stop_gradient(-x + tf.round(x))\n\n  File \"/usr/local/lib/python3.8/dist-packages/tensorflow/python/util/traceback_utils.py\", line 153, in error_handler\n    raise e.with_traceback(filtered_tb) from None\n\n  File \"/usr/local/lib/python3.8/dist-packages/tensorflow/python/framework/ops.py\", line 6656, in raise_from_not_ok_status\n    raise core._status_to_exception(e) from None  # pylint: disable=protected-access\n\ntensorflow.python.framework.errors_impl.ResourceExhaustedError: {{function_node __wrapped__AddV2_device_/job:localhost/replica:0/task:0/device:GPU:0}} failed to allocate memory [Op:AddV2] name: \n\n\n\t [[{{node PyFunc}}]]\n\t [[IteratorGetNext]]\n0 successful operations.\n0 derived errors ignored. [Op:__inference_predict_function_1506]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mUnknownError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# predicts test data\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m p_test \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtest_generator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      4\u001b[0m complete_truth \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m _, y \u001b[38;5;129;01min\u001b[39;00m test_generator:\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/keras/src/utils/traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[1;32m     68\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[1;32m     69\u001b[0m     \u001b[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[0;32m---> 70\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     71\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m     72\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/execute.py:53\u001b[0m, in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     52\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[0;32m---> 53\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m pywrap_tfe\u001b[38;5;241m.\u001b[39mTFE_Py_Execute(ctx\u001b[38;5;241m.\u001b[39m_handle, device_name, op_name,\n\u001b[1;32m     54\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[1;32m     55\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     56\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[0;31mUnknownError\u001b[0m: Graph execution error:\n\n2 root error(s) found.\n  (0) UNKNOWN:  ResourceExhaustedError: {{function_node __wrapped__AddV2_device_/job:localhost/replica:0/task:0/device:GPU:0}} failed to allocate memory [Op:AddV2] name: \nTraceback (most recent call last):\n\n  File \"/usr/local/lib/python3.8/dist-packages/tensorflow/python/ops/script_ops.py\", line 268, in __call__\n    ret = func(*args)\n\n  File \"/usr/local/lib/python3.8/dist-packages/tensorflow/python/autograph/impl/api.py\", line 643, in wrapper\n    return func(*args, **kwargs)\n\n  File \"/usr/local/lib/python3.8/dist-packages/tensorflow/python/data/ops/from_generator_op.py\", line 198, in generator_py_func\n    values = next(generator_state.get_iterator(iterator_id))\n\n  File \"/usr/local/lib/python3.8/dist-packages/keras/src/engine/data_adapter.py\", line 917, in wrapped_generator\n    for data in generator_fn():\n\n  File \"/usr/local/lib/python3.8/dist-packages/keras/src/engine/data_adapter.py\", line 1064, in generator_fn\n    yield x[i]\n\n  File \"/home/dajiang/smart-pixels-ml/dataloaders/OptimizedDataGenerator_v2.py\", line 587, in __getitem__\n    X_batch = QKeras_data_prep_quantizer(X_batch, bits=4, int_bits=0, alpha=1)\n\n  File \"/home/dajiang/smart-pixels-ml/dataloaders/OptimizedDataGenerator_v2.py\", line 37, in QKeras_data_prep_quantizer\n    return quantizer(data)\n\n  File \"/home/dajiang/.local/lib/python3.8/site-packages/qkeras/quantizers.py\", line 634, in __call__\n    _round_through(p, self.use_stochastic_rounding, precision=1.0),\n\n  File \"/home/dajiang/.local/lib/python3.8/site-packages/qkeras/quantizers.py\", line 326, in _round_through\n    output = x + tf.stop_gradient(-x + tf.round(x))\n\n  File \"/usr/local/lib/python3.8/dist-packages/tensorflow/python/util/traceback_utils.py\", line 153, in error_handler\n    raise e.with_traceback(filtered_tb) from None\n\n  File \"/usr/local/lib/python3.8/dist-packages/tensorflow/python/framework/ops.py\", line 6656, in raise_from_not_ok_status\n    raise core._status_to_exception(e) from None  # pylint: disable=protected-access\n\ntensorflow.python.framework.errors_impl.ResourceExhaustedError: {{function_node __wrapped__AddV2_device_/job:localhost/replica:0/task:0/device:GPU:0}} failed to allocate memory [Op:AddV2] name: \n\n\n\t [[{{node PyFunc}}]]\n\t [[IteratorGetNext]]\n\t [[IteratorGetNext/_2]]\n  (1) UNKNOWN:  ResourceExhaustedError: {{function_node __wrapped__AddV2_device_/job:localhost/replica:0/task:0/device:GPU:0}} failed to allocate memory [Op:AddV2] name: \nTraceback (most recent call last):\n\n  File \"/usr/local/lib/python3.8/dist-packages/tensorflow/python/ops/script_ops.py\", line 268, in __call__\n    ret = func(*args)\n\n  File \"/usr/local/lib/python3.8/dist-packages/tensorflow/python/autograph/impl/api.py\", line 643, in wrapper\n    return func(*args, **kwargs)\n\n  File \"/usr/local/lib/python3.8/dist-packages/tensorflow/python/data/ops/from_generator_op.py\", line 198, in generator_py_func\n    values = next(generator_state.get_iterator(iterator_id))\n\n  File \"/usr/local/lib/python3.8/dist-packages/keras/src/engine/data_adapter.py\", line 917, in wrapped_generator\n    for data in generator_fn():\n\n  File \"/usr/local/lib/python3.8/dist-packages/keras/src/engine/data_adapter.py\", line 1064, in generator_fn\n    yield x[i]\n\n  File \"/home/dajiang/smart-pixels-ml/dataloaders/OptimizedDataGenerator_v2.py\", line 587, in __getitem__\n    X_batch = QKeras_data_prep_quantizer(X_batch, bits=4, int_bits=0, alpha=1)\n\n  File \"/home/dajiang/smart-pixels-ml/dataloaders/OptimizedDataGenerator_v2.py\", line 37, in QKeras_data_prep_quantizer\n    return quantizer(data)\n\n  File \"/home/dajiang/.local/lib/python3.8/site-packages/qkeras/quantizers.py\", line 634, in __call__\n    _round_through(p, self.use_stochastic_rounding, precision=1.0),\n\n  File \"/home/dajiang/.local/lib/python3.8/site-packages/qkeras/quantizers.py\", line 326, in _round_through\n    output = x + tf.stop_gradient(-x + tf.round(x))\n\n  File \"/usr/local/lib/python3.8/dist-packages/tensorflow/python/util/traceback_utils.py\", line 153, in error_handler\n    raise e.with_traceback(filtered_tb) from None\n\n  File \"/usr/local/lib/python3.8/dist-packages/tensorflow/python/framework/ops.py\", line 6656, in raise_from_not_ok_status\n    raise core._status_to_exception(e) from None  # pylint: disable=protected-access\n\ntensorflow.python.framework.errors_impl.ResourceExhaustedError: {{function_node __wrapped__AddV2_device_/job:localhost/replica:0/task:0/device:GPU:0}} failed to allocate memory [Op:AddV2] name: \n\n\n\t [[{{node PyFunc}}]]\n\t [[IteratorGetNext]]\n0 successful operations.\n0 derived errors ignored. [Op:__inference_predict_function_1506]"
     ]
    }
   ],
   "source": [
    "# predicts test data\n",
    "p_test = model.predict(test_generator)\n",
    "\n",
    "complete_truth = None\n",
    "for _, y in test_generator:\n",
    "    if complete_truth is None:\n",
    "        complete_truth = y\n",
    "    else:\n",
    "        complete_truth = np.concatenate((complete_truth, y), axis=0)\n",
    "\n",
    "# creates df with all predicted values and matrix elements - 4 predictions, all 10 unique matrix elements\n",
    "df = pd.DataFrame(p_test,columns=['x','M11','y','M22','cotA','M33','cotB','M44','M21','M31','M32','M41','M42','M43'])\n",
    "\n",
    "# stores all true values in same matrix as xtrue, ytrue, etc.\n",
    "df['xtrue'] = complete_truth[:,0]\n",
    "df['ytrue'] = complete_truth[:,1]\n",
    "df['cotAtrue'] = complete_truth[:,2]\n",
    "df['cotBtrue'] = complete_truth[:,3]\n",
    "df['M11'] = minval+tf.math.maximum(df['M11'], 0)\n",
    "df['M22'] = minval+tf.math.maximum(df['M22'], 0)\n",
    "df['M33'] = minval+tf.math.maximum(df['M33'], 0)\n",
    "df['M44'] = minval+tf.math.maximum(df['M44'], 0)\n",
    "\n",
    "df['sigmax'] = abs(df['M11'])\n",
    "df['sigmay'] = np.sqrt(df['M21']**2 + df['M22']**2)\n",
    "df['sigmacotA'] = np.sqrt(df['M31']**2+df['M32']**2+df['M33']**2)\n",
    "df['sigmacotB'] = np.sqrt(df['M41']**2+df['M42']**2+df['M43']**2+df['M44']**2)\n",
    "\n",
    "# calculates residuals for x, y, cotA, cotB\n",
    "df['residualsX'] = df['xtrue'] - df['x']\n",
    "df['residualsY'] = df['ytrue'] - df['y']\n",
    "df['residualsA'] = df['cotAtrue'] - df['cotA']\n",
    "df['residualsB'] = df['cotBtrue'] - df['cotB']\n",
    "\n",
    "# calculates pulls for x, y, cotA, cotB\n",
    "df['pullx'] = (df['xtrue']-df['x'])/df['sigmax']\n",
    "df['pully'] = (df['ytrue']-df['y'])/df['sigmay']\n",
    "df['pullcotA'] = (df['cotAtrue']-df['cotA'])/df['sigmacotA']\n",
    "df['pullcotB'] = (df['cotBtrue']-df['cotB'])/df['sigmacotB']\n",
    "\n",
    "# stores results as parquet\n",
    "df.to_parquet(\"/home/dajiang/smart-pixels-ml/processed_parquets/dataset_3src_16x16/test-dataset_3src_16x16/{}_bs{}_{}_{}t_train-dataset_3src_16x16_test-dataset_3src_16x16_nonquantized-input_vars.parquet\".format(pitch, batch_size, fingerprint, timeslices))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7244d23f-ffb6-40ba-b619-c1250554de45",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
